{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import Uniform\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.set_seed(42)\n",
    "\n",
    "M = 128  # batch size during training\n",
    "d = 100  # latent dimension\n",
    "\n",
    "DATA_DIR = \"data/mnist\"\n",
    "IMG_DIR = \"img\"\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "if not os.path.exists(IMG_DIR):\n",
    "    os.makedirs(IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(DATA_DIR)\n",
    "x_ph = tf.placeholder(tf.float32, [M, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generative_network(eps):\n",
    "    h1 = slim.fully_connected(eps, 128, activation_fn=tf.nn.relu)\n",
    "    x = slim.fully_connected(h1, 784, activation_fn=tf.sigmoid)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Gen\"):\n",
    "    eps = Uniform(tf.zeros([M, d]) - 1.0, tf.ones([M, d]))\n",
    "    x = generative_network(eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminative_network(x):\n",
    "    \"\"\"Outputs probability in logits.\"\"\"\n",
    "    h1 = slim.fully_connected(x, 128, activation_fn=tf.nn.relu)\n",
    "    logit = slim.fully_connected(h1, 1, activation_fn=None)\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "optimizer_d = tf.train.AdamOptimizer()\n",
    "\n",
    "inference = ed.GANInference(data={x: x_ph}, discriminator=discriminative_network)\n",
    "inference.initialize(\n",
    "    optimizer=optimizer, optimizer_d=optimizer_d,\n",
    "    n_iter=15000, n_print=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [100%] ██████████████████████████████ Elapsed: 226s | Disc Loss: 0.464 | Gen Loss: 2.588\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(M, size=16)\n",
    "i = 0\n",
    "for t in range(inference.n_iter):\n",
    "    if t % inference.n_print == 0:\n",
    "        samples = sess.run(x)\n",
    "        samples = samples[idx, ]\n",
    "        \n",
    "        fig = plot(samples)\n",
    "        plt.savefig(os.path.join(IMG_DIR, '{}.png').format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        i += 1\n",
    "    x_batch, _ = mnist.train.next_batch(M)\n",
    "    info_dict = inference.update(feed_dict={x_ph: x_batch})\n",
    "    inference.print_progress(info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Reshape, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = 128  # batch size during training\n",
    "d = 100  # latent dimension\n",
    "\n",
    "DC_DATA_DIR = \"data/dc_mnist\"\n",
    "DC_IMG_DIR = \"dc_img\"\n",
    "\n",
    "if not os.path.exists(DC_DATA_DIR):\n",
    "    os.makedirs(DC_DATA_DIR)\n",
    "if not os.path.exists(DC_IMG_DIR):\n",
    "    os.makedirs(DC_IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(DATA_DIR)\n",
    "x_ph = tf.placeholder(tf.float32, [M, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dc_generative_network(eps):\n",
    "    x = slim.fully_connected(eps, 1024)\n",
    "    x = slim.batch_norm(x, activation_fn=tf.nn.relu)\n",
    "    x = slim.fully_connected(x, 128*7*7, activation_fn=tf.nn.relu)\n",
    "    x = slim.batch_norm(x, activation_fn=tf.nn.relu)\n",
    "    x = tf.reshape(x, [-1, 7, 7, 128])\n",
    "    x = slim.conv2d_transpose(x, 64, [5, 5], stride=2)\n",
    "    x = slim.batch_norm(x, activation_fn=tf.nn.relu)\n",
    "    x = slim.conv2d_transpose(x, 1, [5, 5], stride=2, activation_fn=tf.sigmoid)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"GC_Gen\"):\n",
    "    gc_eps = Uniform(tf.zeros([M, d]) - 1.0, tf.ones([M, d]))\n",
    "    x = dc_generative_network(gc_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha):\n",
    "    return tf.maximum(alpha*x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dc_discriminative_network(x):\n",
    "    x = slim.conv2d(x, 64, [5, 5], stride=2)\n",
    "    x = leaky_relu(x, 0.2)\n",
    "    x = slim.conv2d(x, 128, [5, 5], stride=2)\n",
    "    x = leaky_relu(x, 0.2)\n",
    "    x = slim.fully_connected(x, 256)\n",
    "    x = leaky_relu(x, 0.2)\n",
    "    x = slim.dropout(x)\n",
    "    logit = slim.fully_connected(x, 1, activation_fn=tf.sigmoid)\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc_optimizer = tf.train.AdamOptimizer()\n",
    "gc_optimizer_d = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inference = ed.GANInference(data={x: x_ph}, discriminator=dc_discriminative_network)\n",
    "inference.initialize(\n",
    "    optimizer=gc_optimizer, optimizer_d=gc_optimizer_d,\n",
    "    n_iter=15000, n_print=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [100%] ██████████████████████████████ Elapsed: 9314s | Disc Loss: 1.386 | Gen Loss: 0.693\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(M, size=16)\n",
    "i = 0\n",
    "for t in range(inference.n_iter):\n",
    "    if t % inference.n_print == 0:\n",
    "        samples = sess.run(x)\n",
    "        samples = samples[idx, ]\n",
    "        \n",
    "        fig = plot(samples)\n",
    "        plt.savefig(os.path.join(DC_IMG_DIR, '{}.png').format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        i += 1\n",
    "    x_batch, _ = mnist.train.next_batch(M)\n",
    "    x_batch = x_batch.reshape( [M, 28, 28, 1])\n",
    "    info_dict = inference.update(feed_dict={x_ph: x_batch})\n",
    "    inference.print_progress(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
